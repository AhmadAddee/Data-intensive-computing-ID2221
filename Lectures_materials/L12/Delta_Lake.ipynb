{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y thinc opencv-python opencv-contrib-python opencv-python-headless"
      ],
      "metadata": {
        "id": "3t9oyF-18JYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PYVAmTgX53AR"
      },
      "outputs": [],
      "source": [
        "# Install Java 11 (works well with Spark 3.5.x)\n",
        "!apt-get -y install openjdk-11-jdk > /dev/null\n",
        "\n",
        "# Install PySpark (bundles Spark 3.5.6)\n",
        "!pip -q install \"pyspark[connect]==3.5.6\" \"delta-spark==3.2.0\"\n",
        "\n",
        "# No \"SPARK_HOME\" needed on Colab.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] += \":/usr/lib/jvm/java-11-openjdk-amd64/bin\"\n",
        "\n",
        "# Make sure old envs don't override this session\n",
        "os.environ.pop(\"SPARK_HOME\", None)\n",
        "os.environ.pop(\"PYSPARK_SUBMIT_ARGS\", None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_delta_spark():\n",
        "  from pyspark.sql import SparkSession\n",
        "  from delta import configure_spark_with_delta_pip\n",
        "  builder = SparkSession.builder.appName(\"DeltaLakeApp\") \\\n",
        "  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
        "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\\\n",
        "  .config(\"spark.jars.packages\",\"io.delta:delta-core_2.12:2.0.0\")\n",
        "  return configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "\n",
        "spark = _create_delta_spark()"
      ],
      "metadata": {
        "id": "yNNWqBM17ip1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading some data already available in Google Colab under `sample_data` folder."
      ],
      "metadata": {
        "id": "y9y99aklBe-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read sample data\n",
        "df = spark.read.options(inferSchema=True, header=True).csv(\"/content/sample_data/california_housing_train.csv\")\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LInIkG_U8fnf",
        "outputId": "8c6d19b1-02db-4a09-9ff5-6391b0ada617"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- housing_median_age: double (nullable = true)\n",
            " |-- total_rooms: double (nullable = true)\n",
            " |-- total_bedrooms: double (nullable = true)\n",
            " |-- population: double (nullable = true)\n",
            " |-- households: double (nullable = true)\n",
            " |-- median_income: double (nullable = true)\n",
            " |-- median_house_value: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a database to create our delta table under."
      ],
      "metadata": {
        "id": "Q1MDT_XqBpLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a database\n",
        "spark.sql(\"create database my_demo\")\n",
        "spark.sql(\"use my_demo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2Hm1NnT8r0-",
        "outputId": "d133ef29-9989-4b7e-9433-b8716fbdda2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can write the data in the delta format."
      ],
      "metadata": {
        "id": "9L_vpR5MB3gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write csv data as deltap\n",
        "df.write.mode(\"overwrite\").format(\"delta\").save(\"my_demo/df_delta\")"
      ],
      "metadata": {
        "id": "mJ-5eqeK-h09"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And, read in the delta format."
      ],
      "metadata": {
        "id": "9cPK_G99B-6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read delta table\n",
        "df_delta = spark.read.format(\"delta\").load(\"my_demo/df_delta\")"
      ],
      "metadata": {
        "id": "YjcEl3Tj-q4q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_delta.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBzdWdmX_Jpo",
        "outputId": "aee94476-d58e-4735-e970-a355faf0416f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's read the delta table and add a new column to it as below.\n"
      ],
      "metadata": {
        "id": "QoJv-04ZCKox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new column in housing_df_delta dataframe with the name \"median_house_value_new\" and its values as \"median_house_value\"*1.1\n",
        "df_delta = df_delta.withColumn(\"median_house_value_new\", df_delta[\"median_house_value\"] * 1.1)\n",
        "df_delta.show(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a025ad-4a62-4b4d-8e35-c9e96742ecda",
        "id": "IrdYns3v-3Uy"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+----------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|median_house_value_new|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+----------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|               73590.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+----------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we know that the already saved files and the files have a schema difference, we need to pass an option `mergeSchema`."
      ],
      "metadata": {
        "id": "8bqvcfiTCT3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_delta.write\\\n",
        ".option(\"mergeSchema\", \"true\")\\\n",
        ".mode(\"append\").format(\"delta\").save(\"my_demo/df_delta\")"
      ],
      "metadata": {
        "id": "t0_bgp67ADB3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's the read the available versions for our delta table as below. I have 2 versions: version 0 is the table creation version and version 1 is the changed schema write version."
      ],
      "metadata": {
        "id": "-4rA38gFClNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Delta table\n",
        "from delta import DeltaTable\n",
        "deltaTable = DeltaTable.forPath(spark, \"my_demo/df_delta\")\n",
        "\n",
        "#View history\n",
        "history = deltaTable.history().show(truncate =False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcghpO4kAGzp",
        "outputId": "aa82dde9-89d0-492f-a7f8-326132d9a366"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------+------------+-----------------------------------+\n",
            "|version|timestamp              |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                 |userMetadata|engineInfo                         |\n",
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------+------------+-----------------------------------+\n",
            "|1      |2025-09-27 07:18:33.077|NULL  |NULL    |WRITE    |{mode -> Append, partitionBy -> []}   |NULL|NULL    |NULL     |0          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 17000, numOutputBytes -> 382376}|NULL        |Apache-Spark/3.5.6 Delta-Lake/3.2.0|\n",
            "|0      |2025-09-27 07:13:08.14 |NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 17000, numOutputBytes -> 337740}|NULL        |Apache-Spark/3.5.6 Delta-Lake/3.2.0|\n",
            "+-------+-----------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+-----------------------------------------------------------------+------------+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's read the 0th version of the delta table. Observe the output that we don't have the newly added column."
      ],
      "metadata": {
        "id": "_EpFBBAMC6WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read version 0\n",
        "version0DF = spark.read.format(\"delta\")\\\n",
        "  .option(\"versionAsOf\", 0)\\\n",
        "  .load(\"my_demo/df_delta\")\n",
        "\n",
        "version0DF.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s39Rwa0ARQ_",
        "outputId": "5bebbd20-986d-488c-ca05-3f3b22d40e14"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whereas if you read version 1 of the delta table, we have the newly added column available."
      ],
      "metadata": {
        "id": "2L6DdEaGDHGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read version 1\n",
        "version1DF = spark.read.format(\"delta\")\\\n",
        "  .option(\"versionAsOf\", 1)\\\n",
        "  .load(\"my_demo/df_delta\")\n",
        "\n",
        "version1DF.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t5JwkH8ATdg",
        "outputId": "959e9f37-4b93-4f66-b836-e7a0c99cb38d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+----------------------+\n",
            "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|median_house_value_new|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+----------------------+\n",
            "|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|                  NULL|\n",
            "|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|                  NULL|\n",
            "|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|                  NULL|\n",
            "|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|                  NULL|\n",
            "|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|                  NULL|\n",
            "|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|                  NULL|\n",
            "|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|                  NULL|\n",
            "|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|                  NULL|\n",
            "|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|                  NULL|\n",
            "|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|                  NULL|\n",
            "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+----------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vClOhQfX_aO3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}